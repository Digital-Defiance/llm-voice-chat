name: "ASA Dataset - Note: this workflow is meant to be run locally"

on:
  workflow_dispatch:
    inputs:
      action:
        description: "Action to run"
        required: true
        default: "download-and-extract-data"
        options:
          - "download-and-extract-data"
          - "preprocess-data"


env:
  AWS_REGION: eu-south-1
  RAW_DATASET_URL: https://github.com/Digital-Defiance/llm-voice-chat/releases/download/dataset-release-amazon-reviews/original_amazon_review_full_csv.tar.gz
  PYTHONPATH: /workspaces/llm-voice-chat/data/asa
  TMP_FOLDER: /workspaces/llm-voice-chat/data/tmp
  CSV_TRAIN: amazon_review_full_csv/train.csv
  CSV_TEST: amazon_review_full_csv/test.csv


jobs:
  download-and-extract-data:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.action == 'download-and-extract-data' }}
    name: Download and extract data
    steps:
      - name: Check if raw dataset exists
        id: check_raw_dataset
        continue-on-error: true
        run: test -f ${{ env.TMP_FOLDER }}/original_amazon_review_full_csv.tar.gz
  
      - name: Download raw dataset
        id: download_raw_dataset
        if: steps.check_raw_dataset.outcome != 'success'
        run: curl -L $RAW_DATASET_URL -o ${{ env.TMP_FOLDER }}/original_amazon_review_full_csv.tar.gz
    
      - name: Extract files
        if: steps.download_raw_dataset.outcome == 'success'
        run: tar -xvf ${{ env.TMP_FOLDER }}/original_amazon_review_full_csv.tar.gz -C ${{ env.TMP_FOLDER }}
    
      - name: List files
        run: ls -la ${{ env.TMP_FOLDER }}/amazon_review_full_csv
  

  preprocess-data:
    if: ${{ github.event.inputs.action == 'preprocess-data' }}
    runs-on: ubuntu-latest
    name: Preprocess data
    needs: download-and-extract-data
    strategy:
      max-parallel: 1
      matrix:
        split: ["test", "train"]
    steps:
      - name: Check if path exists
        id: check_path
        continue-on-error: true
        run: test -d ${{ env.TMP_FOLDER }}/amazon_review_full_csv/${{ matrix.split }}

      - name: Print Data
        shell: python
        # path does not exist
        if: steps.check_path.outcome != 'success'
        run: |
          from pipeline_utils import *
          get_or_create_spark_session()
          (
              input("${{ env.TMP_FOLDER }}/amazon_review_full_csv/${{ matrix.split }}.csv")
              >> csv(header = False, inferSchema = False, escape = '"', multiLine = True, mode = "FAILFAST", schema=CSV_SCHEMA) 
              >> preprocess_text
              >> encode_dataframe_text
              >> select("*", expr("size(text) as size"))
              >> filter(col("size") <= 250)
              >> select(
                  "rating",
                  expr(f"concat(text, array_repeat({PAD_TOKEN}, 250 - size(text))) as text")
              )
              >> repartition(10)
              >> write_parquet("${{ env.TMP_FOLDER }}/amazon_review_full_csv/${{ matrix.split }}")
              >> show()
          )()
      
      - name: Check if path exists
        id: check_path_npz
        continue-on-error: true
        run: test -d /workspaces/llm-voice-chat/data/asa/${{ matrix.split }}.npz

      - name: Preprocess Data To Numpy
        if: steps.check_path_npz.outcome != 'success'
        shell: python
        run: |
          import os
          from pipeline_utils import *
          get_or_create_spark_session()
          current_tmp_path = "${{ env.TMP_FOLDER }}/amazon_review_full_csv/${{ matrix.split }}"
          rating = np.array([0], dtype=np.uint8)
          text = np.array([[0] * 250], dtype=np.uint16)
          for dirname, _, filenames in os.walk(current_tmp_path):
              for filename in filenames:
                  if filename.endswith(".parquet"):
                      path = os.path.join(dirname, filename)
                      print(path)
                      rating_slice, text_slice = (
                          input(path)
                          >> read_parquet()
                          >> collect()
                          >> columns_to_numpy
                      )()

                      rating = np.append(rating, rating_slice)
                      text = np.append(text, text_slice, axis=0)
                      print(text.shape, rating.shape)

          np.savez_compressed(
            "/workspaces/llm-voice-chat/data/asa/${{ matrix.split }}.npz",
            rating=rating[1:],
            text=text[1:]
          )

