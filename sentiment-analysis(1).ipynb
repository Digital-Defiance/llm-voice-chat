{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7537439,"sourceType":"datasetVersion","datasetId":4389230}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport polars as pl\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat /kaggle/input/amazon-review-full-csv/amazon_review_full_csv/readme.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tiktoken pyspark\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n    .master(\"local[*]\") \\\n    .appName(\"PySpark_Tutorial\") \\\n    .config(\"spark.driver.memory\", \"10g\") \\\n    .config(\"spark.executor.memory\", \"10g\") \\\n    .getOrCreate()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T16:05:06.502988Z","iopub.execute_input":"2024-02-02T16:05:06.503499Z","iopub.status.idle":"2024-02-02T16:05:12.292008Z","shell.execute_reply.started":"2024-02-02T16:05:06.503461Z","shell.execute_reply":"2024-02-02T16:05:12.290928Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/02/02 16:05:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import udf\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import ArrayType, IntegerType\nimport tiktoken\nimport numpy as np\n\nPATH_TRAIN_DATA = \"/kaggle/input/amazon-review-full-csv/amazon_review_full_csv/train.csv\"\nPATH_TEST_DATA = \"/kaggle/input/amazon-review-full-csv/amazon_review_full_csv/test.csv\"\nrating_encodings = [\n    [1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 1, 0, 0],\n    [0, 0, 0, 1, 0],\n    [0, 0, 0, 0, 1],\n]\n\n\ndef as_udf(output_annotation):\n    def wrapper(func):\n        return udf(func, output_annotation)\n    return wrapper\n\n@as_udf(ArrayType(IntegerType()))\ndef encode_rating(rating: str):\n    return rating_encodings[int(rating[-1]) - 1]\n\n@as_udf(ArrayType(IntegerType()))\ndef encode_text(text):\n    gpt2_encoder = tiktoken.get_encoding(\"gpt2\")\n    text = text[:-1]\n    encoded_text = gpt2_encoder.encode(text)\n    len_encoded_text = len(encoded_text)\n    return encoded_text + (700 - len_encoded_text)*[0]\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T16:05:12.294247Z","iopub.execute_input":"2024-02-02T16:05:12.295153Z","iopub.status.idle":"2024-02-02T16:05:13.737567Z","shell.execute_reply.started":"2024-02-02T16:05:12.295116Z","shell.execute_reply":"2024-02-02T16:05:13.735986Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/amazon-review-full-csv/amazon_review_full_csv/train.csv\"\ndf_raw = spark.read.csv(path, header=False, inferSchema=True, sep='\",\"')\ndf = df_raw.withColumn(\"_c0_1\", encode_rating(df_raw._c0))\ndf = df.withColumn(\"_c2_1\", encode_text(df_raw._c2))\ndf = df.select(\n    df._c0_1, \n    df._c2_1,\n)\ndf.coalesce(1).write.parquet(\"train2.parquet\")\ndel df_raw, df","metadata":{"execution":{"iopub.status.busy":"2024-02-02T16:05:17.433826Z","iopub.execute_input":"2024-02-02T16:05:17.434236Z","iopub.status.idle":"2024-02-02T16:19:26.828237Z","shell.execute_reply.started":"2024-02-02T16:05:17.434206Z","shell.execute_reply":"2024-02-02T16:19:26.827240Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"data = spark.read.parquet(\"/kaggle/working/train2.parquet\") ","metadata":{"execution":{"iopub.status.busy":"2024-02-02T16:21:12.461251Z","iopub.execute_input":"2024-02-02T16:21:12.461737Z","iopub.status.idle":"2024-02-02T16:21:12.791702Z","shell.execute_reply.started":"2024-02-02T16:21:12.461704Z","shell.execute_reply":"2024-02-02T16:21:12.789951Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.offset(50_000).limit(50_000).show()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T16:21:58.034705Z","iopub.execute_input":"2024-02-02T16:21:58.035152Z","iopub.status.idle":"2024-02-02T16:22:12.613783Z","shell.execute_reply.started":"2024-02-02T16:21:58.035117Z","shell.execute_reply":"2024-02-02T16:22:12.612668Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"[Stage 8:============================================>              (3 + 1) / 4]\r","output_type":"stream"},{"name":"stdout","text":"+---------------+--------------------+\n|          _c0_1|               _c2_1|\n+---------------+--------------------+\n|[0, 1, 0, 0, 0]|[1212, 318, 517, ...|\n|[0, 1, 0, 0, 0]|[3260, 3555, 1353...|\n|[0, 0, 0, 0, 1]|[1212, 318, 257, ...|\n|[0, 0, 0, 0, 1]|[40, 1101, 6655, ...|\n|[0, 0, 1, 0, 0]|[40, 373, 11679, ...|\n|[0, 0, 0, 0, 1]|[464, 2342, 318, ...|\n|[0, 0, 0, 1, 0]|[11980, 12666, 50...|\n|[0, 0, 1, 0, 0]|[464, 287, 6753, ...|\n|[1, 0, 0, 0, 0]|[4711, 443, 1130,...|\n|[1, 0, 0, 0, 0]|[40, 5839, 777, 7...|\n|[0, 1, 0, 0, 0]|[20, 6, 20, 15931...|\n|[0, 0, 1, 0, 0]|[40, 588, 262, 20...|\n|[0, 0, 1, 0, 0]|[4711, 443, 1130,...|\n|[0, 0, 1, 0, 0]|[27218, 443, 1130...|\n|[0, 0, 1, 0, 0]|[21902, 13822, 30...|\n|[0, 0, 0, 0, 1]|[1212, 1720, 318,...|\n|[0, 1, 0, 0, 0]|[40, 1101, 642, 6...|\n|[0, 1, 0, 0, 0]|[40, 1422, 470, 1...|\n|[0, 0, 0, 1, 0]|[35422, 1068, 777...|\n|[0, 0, 1, 0, 0]|[40, 588, 777, 44...|\n+---------------+--------------------+\nonly showing top 20 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \ndef read(idx):\n    b = data.offset(idx*50_000).limit(50_000)\n    x = np.array(b.select(b._c2_1).collect())[:, 0, :]\n    y = np.array(b.select(b._c0_1).collect())[:, 0, :]\n    return x, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"read(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}