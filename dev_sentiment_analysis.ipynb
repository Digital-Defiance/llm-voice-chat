{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  464,  4631,   318,  ..., 50258, 50258, 50258],\n",
      "        [  464, 17177,  3481,  ..., 50258, 50258, 50258],\n",
      "        [   50,  3889, 11139,  ..., 50258, 50258, 50258],\n",
      "        ...,\n",
      "        [ 1135,   705,   303,  ..., 50258, 50258, 50258],\n",
      "        [ 9360,  3296,  6807,  ..., 50258, 50258, 50258],\n",
      "        [  818,   428,  1339,  ..., 50258, 50258, 50258]])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from model import ModelFactory\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "model_factory = ModelFactory(\n",
    "    coordinates = 100,\n",
    "    words = 101,\n",
    "    tokens=50258 + 3,\n",
    "    number_of_blocks = 10,\n",
    "    \n",
    "    number_of_heads = 3,\n",
    "    bias = False,\n",
    "    attention = \"metric\"# \"scaled_dot_product\", # or \"metric\"\n",
    ")\n",
    "\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = model_factory.create_model(kind=\"encoder\")\n",
    "        del self.model[-1]\n",
    "        del self.model[-1]\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.LayerNorm(model_factory.coordinates),\n",
    "            nn.Linear(model_factory.coordinates, model_factory.coordinates),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(model_factory.coordinates, model_factory.coordinates),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(model_factory.coordinates // 2, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sequence_bw: Tensor) -> Tensor:\n",
    "        sequence_bwc = self.model(sequence_bw)\n",
    "        sequence_bc = sequence_bwc.mean(dim=1) # average over words\n",
    "        sequence_bv = self.classification_head(sequence_bc)\n",
    "        return sequence_bv\n",
    "\n",
    "with open(\"stanfordSentimentTreebank.pickle\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "sentence_Bw = dataset['train'][0]\n",
    "sentence_Bw = torch.tensor(sentence_Bw)\n",
    "print(sentence_Bw)\n",
    "\n",
    "SentimentModel()(sentence_Bw[0:32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SentimentModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, size, \u001b[38;5;241m32\u001b[39m):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(sentences[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m32\u001b[39m]), torch\u001b[38;5;241m.\u001b[39mtensor(sentiments[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m32\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentimentModel\u001b[49m()\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     15\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentimentModel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"here\")\n",
    "\n",
    "\n",
    "def yieldtrainingdata():\n",
    "\n",
    "    sentences, sentiments = dataset['train']\n",
    "    \n",
    "    size = len(sentences)\n",
    "    for i in range(0, size, 32):\n",
    "        yield torch.tensor(sentences[i:i+32]), torch.tensor(sentiments[i:i+32])\n",
    "\n",
    "\n",
    "model = SentimentModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for sentence_bw, sentiment_b in yieldtrainingdata():\n",
    "        optimizer.zero_grad()\n",
    "        pred_logits_bv = model(sentence_bw)\n",
    "        loss_train = loss_function(pred_logits_bv, sentiment_b)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        print(loss_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# special_tokens\n",
    "gpt2_encoder = tiktoken"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
